

git remote set-url origin git@github.com:danchurch/nanoporeHostDepletionSpruce.git

git push -u origin main


## Chris Nuske has been working really hard to 
## get adaptive sampling working for the lab.
## let's see if we can catch up with Chris a bit,

## we'll work mostly on the lab nanopore computer,
## so readfish installs, etc will be there.

## he has scripts here:

## keeping a github repo here:
https://github.com/danchurch/nanoporeHostDepletionSpruce

## first step is to get ReadFish installed in a conda environment,
## on my account on the lab computer.

## we'll follow their instructions on github:
https://github.com/looselab/readfish

## we'll put a copy of their yaml file on the labcomp here:

cd /media/vol1/daniel/hostDepletion

conda env create -f readfish_env.yml

conda activate readfish

readfish

## seems to work. 

## according to Chris, it's important to add ourselves
## to the minknow user group:

groups test

sudo usermod -a -G minknow test

## we can watch minknow on our extra office computer
## do this by clicking on lower left "connection manager"
## and entering the nanoComp computer IP addess:
132.180.112.115

## to test it out, we need a bulk fast5 file
## chris already downloaded a sample bulk fast five,
## it's here

ls /home/chris/PLSP57501_simulation.fast5


## link for me
ln -s /home/chris/PLSP57501_simulation.fast5 /media/vol1/daniel/hostDepletion/sampleBulk.fast5 

## link for lara
sudo ln -s /home/chris/PLSP57501_simulation.fast5 /media/vol2/lara/sampleBulk.fast5 

## we need a TOML file. instructions are here:
https://github.com/LooseLab/readfish/blob/dev_staging/TOML.md

## chris has already worked through a lot of the gotchas
## on the TOML file...

## some are here:
ls /home/chris/*.toml

## also one here, but not what we need, I think.
/media/vol2/chris/channels.toml


## this might be a good one:
less /home/chris/pabies_depletion.toml

## let's make a copy of that for us to play with:

cd /media/vol1/daniel/hostDepletion/

cp  /home/chris/pabies_depletion.toml /media/vol1/daniel/hostDepletion/

## what do we need to change for this?

## the tutorial also mentions using existing toml files 
## from  minknow for templates:

cd /opt/ont/minknow/conf/package/sequencing/

## ah, and I see these sequencing toml files are very different
## from the readfish toml files for adaptice samplig

## chris has already modified this one to look for for his 
## bulkfast5 example like we are doing now:

less /opt/ont/minknow/conf/package/sequencing/sequencing_MIN106_DNA.toml

## back it up, then play with it

cd /opt/ont/minknow/conf/package/sequencing/

cp sequencing_MIN106_DNA.toml sequencing_MIN106_DNA.toml.bk
chmod 444 sequencing_MIN106_DNA.toml.bk

## to keep track of differences
diff sequencing_MIN106_DNA.toml.bk sequencing_MIN106_DNA.toml

## changed the following, under # Sequencing Feature Settings # --> # basic_settings # --> [custom_settings]

"""
simulation = "/media/vol1/daniel/hostDepletion/sampleBulk.fast5"
"""

## changing file to find my bulk fast5 file
## chris already change alignment time limit settings

## we then setup a run using the config test flowcell, 
## and setting the flow cell type to match whatever 
## sequencing toml file we modified (in this case MIN106 DNA, above)

## run started.

## we should be able to eject (reject) all reads currently in 
## pores with readfish:

readfish unblock-all --device MN40608 --experiment-name "Testing ReadFish Unblock All"

## the device id is the same as the "position" reported by minknow

## do I need to match the experiment name? nope

## that should just mean that all reads are rejected

## funny, it looks to me like it is still reported the basecalling
## from these unblocked reads, just as very short sequences.

## anyway, looks like it is working. 

## stop run and clean up the files,,,

## files are usually stored here:
/var/lib/minknow/data

## and now let's test their example for enrichment/depletion
## with human chromosome:

## their toml file for enriching a human chromosome:

wget https://raw.githubusercontent.com/LooseLab/readfish/master/examples/human_chr_selection.toml

## we need a human genome and mmi index of it. I think chris 
## found exactly the same genome as is used in their 
## example...

cd /media/vol1/daniel/hostDepletion/

ln -s /home/chris/hg38.fa /media/vol1/daniel/hostDepletion/hg38.fa

## for lara:
sudo ln -s /home/chris/hg38.fa /media/vol2/lara/hg38.fa
ls /home/chris/hg38.fa 
/media/vol1/daniel/hostDepletion/hg38.fa

## make an mmi
minimap2 -d hg38.mmi hg38.fa

## put this in our readfish toml file 

## check the validity of our toml file:

readfish validate 

readfish validate human_chr_selection.toml

## looks good. 

## started a simulation run on minknow. 
## now with readfish

conda activate readfish

cd /media/vol1/daniel/hostDepletion

readfish targets --device MN40608 \
              --experiment-name "debugging22_8_23_try3" \
              --toml /media/vol1/daniel/hostDepletion/human_chr_selection.toml \
              --log-file ru_test.log


less /media/vol1/daniel/hostDepletion/human_chr_selection.toml 


## doesn't work, freezes. possibly due to the guppy server issues 
## chris mentioned. 

## not really sure what this is, a pipe or somethiing,
## but I think we need to change its permissions:

sudo chmod 775 /tmp/.guppy/5555

ls -l /tmp/.guppy/5555

#sudo chmod 777 /tmp/.guppy/5555

## chris has this line for starting a new basecall server:

guppy_basecall_server --config dna_r9.4.1_450bps_fast.cfg -p 5555 -l /tmp/guppy -x 'cuda:0'

## already in use. Stop run and try again. works, but do we really need two guppy 
## servers running?

## generally, you don't. It is just that the config file for guppy might not be right for 
## the simulation. In our case, we using r10 cells for actual data collection, but the 
## simulation requires the older guppy configuration file.


## checklist for getting minion, readfish, and guppy working together for the 
## tutorial:

## make sure a simulated run actually starts with minion. Might take several tries,
## a lot of times errors pop up, when messages like "script failure",
## "internal error", etc. And all you can do is restart the run and/or 
## restart the computer. 

## make sure guppy is running with the right config file. The fast5 files in the
## readfish tutorial are made with an older r9 flow cell, so guppy will 
## probably perform better with the "dna_r9.4.1_450bps_fast.cfg" setting.
## change to this config file, and restart the guppy service.
## to see how to do this, search "resetting guppy with a new config file" below

## make sure guppy client and guppy server are the same version

## make sure you as a user are a member of the minknow group, because...

## make sure the right file permissions are in place for the minknow group,
## not just the minknow user, can access the port for guppy 
## this is usually the /tmp/.guppy/5555 file, indicated in our toml files

sudo chmod 775 /tmp/.guppy/5555

## I had to change the following to the readfish toml:

host= "ipc:///tmp/.guppy/"

## seems to be running. I killed the other manually and it just started again. 
## not sure what to do there. Just leave it I guess

## anyway, with the new basecaller, and the new toml file that looks for it,
## does the above command now work? 

conda activate readfish
readfish targets --device MN40608 \
              --experiment-name "RU Test basecall and map" \
              --toml /media/vol1/daniel/hostDepletion/human_chr_selection.toml \
              --log-file ru_test.log

## nope...

## this issue seems pertinent:
https://github.com/LooseLab/readfish/issues/240

## perhaps also pertinent:
https://github.com/LooseLab/readfish/issues/221

## they mention that our guppy server and client software should line up, version-wise:
guppy_basecall_server --version ## gives us version 6.5.7

pip list | grep pyguppy  ## version 6.4.2

## not the same

## does this help?
pip install ont-pyguppy-client-lib==6.5.7

## they do some diagnostics

## is this necessary to do every time we want to do a 
## new experiment?
ls -l /tmp/.guppy/5555

sudo chmod 775 /tmp/.guppy/5555

less /opt/ont/guppy/data/dna_r9.4.1_450bps_fast.cfg

## they test their guppy server/client with this script:
python -c 'from pyguppy_client_lib.pyclient import PyGuppyClient as PGC; \
           c = PGC("ipc:///tmp/.guppy/5555", "dna_r9.4.1_450bps_fast.cfg"); \
           c.connect(); print(c)'

sudo systemctl status guppyd

## okay, works


readfish targets --device MN40608 \
              --experiment-name "debug_22_8_23_try3" \
              --toml /media/vol1/daniel/hostDepletion/human_chr_selection.toml \
              --log-file readfishtest.log

## and works!!! yay!

## to review,  have to reset user permissions every time guppy server is
## restarted on the socket ./tmp/.guppy/5556
## also need to make sure guppy versions (client and server) match

## so what's next?

## where is the data for this? do I have to stop the run?

## the reads are delivered in batches, here:

/var/lib/minknow/data/zoop5/no_sample/20230628_1557_MN40608_zoop5_f31f0515/fast5_pass

TOML="/media/vol1/daniel/hostDepletion/human_chr_selection.toml"
reads="/var/lib/minknow/data/zoop5"

readfish summary $TOML $reads

## looks like this:

contig  number      sum   min    max    std  mean  median    N50
  chr1    5994  3759112   153  45338   1458   627     487    532
 chr10    2959  1969533   154  49075   2072   666     488    537
 chr11    2949  2046589   200  46773   1861   694     501    561
 chr12    4300  2523930   103  49516   1361   587     494    522
 chr13    2176  1333880   184  39207   1442   613     484    520
 chr14    2917  1940354   179  52401   1949   665     501    543
 chr15    3274  1804635    94  46421   1058   551     472    498
 chr16    1554   970043   192  53194   1912   624     473    517
 chr17    2704  1571430   199  53051   1435   581     486    518
 chr18    2847  1554361   140  15657    612   546     482    503
 chr19    1210   834025   159  21556   1307   689     487    583
  chr2    5918  3675999   130  52366   1354   621     489    530
 chr20    1524  1092416   178  49450   2223   717     496    562
 chr21      30   212798   469  38881   8723  7093    4316  14064
 chr22      55   423294   388  58385  11798  7696    3706  15818
  chr3    5608  3597901   144  61175   1558   642     503    541
  chr4    6637  4105216   155  55008   1667   619     492    535
  chr5    4607  3008922   216  43932   1476   653     494    542
  chr6    4001  2628431   166  54594   1754   657     492    538
  chr7    4103  2343278   145  49974   1057   571     498    524
  chr8    3607  2372494   207  48653   1691   658     493    545
  chr9    2988  1966598   193  46570   1829   658     482    532
  chrM     169   174679   273  16400   2092  1034     543   1135
  chrX    4967  3053079   152  52969   1627   615     479    523
  chrY      14    10745   372   2246    499   768     665    993


## not sure what the "number" column indicates
## but the thing to look for is the median/mean/n50
## the low average read length of the other (not 21/22)
## contigs is indicative that they were rejected 
## after alignment, usually around 500-600 bp in our case.

## I guess this means we would need to exclude low-length reads,
## to exclude the non-targeted reads.

## for making readfish TOMLS, there is a good table on this in the nature paper, table 2.

## for the record, the toml for the above experiment looks like:

"""
[caller_settings]
config_name = "dna_r9.4.1_450bps_hac"
host = "ipc:///tmp/.guppy/"
port = 5555

[conditions]
reference = "/media/vol1/daniel/hostDepletion/hg38.mmi"

[conditions.0]
name = "select_chr_21_22"
control = false
min_chunks = 0
max_chunks = inf
targets = ["chr21", "chr22"]
single_on = "stop_receiving"
multi_on = "stop_receiving"
single_off = "unblock"
multi_off = "unblock"
no_seq = "proceed"
no_map = "proceed"
"""

## the above is modified from:
https://github.com/LooseLab/readfish/blob/master/examples/human_chr_selection.toml


## can we play with this a little? For instance, what happens  if:
## 1) we change "stop_receiving" to "unblock" for all non-target reads?
## 2) we invert, and deplete these two target sequences 
## 3) we block everything that aligns to the genome?


## 1) we change "stop_receiving" to "unblock" for all non-target reads?

cp human_chr_selection.toml human_chr_selection_stop2unblock.toml

## so weird. Looking at their readfish toml, the have everything on 
## target as "stop_receiving". Makes me think that this is the
## command for accepting and sequencing the read. 

## if that is correct, then changing these to unblock would 
## reject most things. I think resulting in everything having
## a read length average of ~500 bp. 

## and just got confirmation from the loose lab github folks

"""
Proceed means that one collects more data for an individual read and you assess it again. Stop_receiving tells the sequencer to keep sequencing that read and not evaluate it again.

So -
unblock means a read will be rejected from the pore and a new one sampled.
proceed means the read will continue to sequence and the next batch of singal will be analysed again.
stop_receiving means send no more data about this read and let it sequence to normal completion.

I hope that helps!
"""

## find this here:
https://github.com/LooseLab/readfish/issues/242

## Let's see. Here is the TOML

## human_chr_selection_stop2unblock.toml
[caller_settings]
config_name = "dna_r9.4.1_450bps_hac"
host = "ipc:///tmp/.guppy/"
port = 5555

[conditions]
reference = "/media/vol1/daniel/hostDepletion/hg38.mmi"

[conditions.0]
name = "select_chr_21_22_stop2unblock"
control = false
min_chunks = 0
max_chunks = inf
targets = ["chr21", "chr22"]
single_on = "unblock"
multi_on = "unblock"
single_off = "unblock"
multi_off = "unblock"
no_seq = "proceed"
no_map = "proceed"

## run the readfish command with this new toml

## as always, make sure we have group permission for the socket
ls -l /tmp/.guppy/5555

conda activate readfish

## check that the client and server are talking:
python -c 'from pyguppy_client_lib.pyclient import PyGuppyClient as PGC; \
           c = PGC("ipc:///tmp/.guppy/5555", "dna_r9.4.1_450bps_fast.cfg"); \
           c.connect(); print(c)'

## yup. onto readfish
readfish targets --device MN40608 \
              --experiment-name "stop_receive2unblock" \
              --toml /media/vol1/daniel/hostDepletion/human_chr_selection_stop2unblock.toml \
              --log-file ru_test.log

## running, let it go for a while


TOML="/media/vol1/daniel/hostDepletion/human_chr_selection_stop2unblock.toml"
reads="/var/lib/minknow/data/zoop7"
readfish summary $TOML $reads

## saving this as stop2unblock.txt, but cleaned up version here:

"""
contig  number      sum   min     max   std  mean  median    N50
  chr1    8166  5297756   162   29411  1084   649     500    547
  chr2   10335  6376134   153   50357  1085   617     491    532
  chr3    7447  4992369   203   29286  1261   670     513    557
  chr4    8234  5712847   110   29541  1290   694     505    571
  chr5    5813  4295677   195   28837  1472   739     500    598
  chr6    5877  3905658   186   67939  1415   665     508    552
  chr7    5915  3850456   133   32864  1092   651     509    550
  chr8    4520  3180204   202   29718  1260   704     511    584
  chr9    4843  3443058   189  166227  2660   711     499    560
 chr10    4548  2948968   162   28674  1098   648     502    549
 chr11    4149  2862933   175   34784  1406   690     498    555
 chr12    4310  3044324   197   55612  1394   706     515    578
 chr13    2912  1845003   206   29650  1132   634     499    541
 chr14    3136  2463883   173   38963  1753   786     510    639
 chr15    5912  3623898   128   89365  1750   613     488    524
 chr16    2234  1589472   169   36303  1413   711     496    599
 chr17    2521  1922530   225   95271  2583   763     501    604
 chr18    4134  2647552   190   70140  1510   640     500    542
 chr19    1635  1494578   183  107938  3081   914     545    807
 chr20    1078  1054159   187   40566  2437   978     533   1051
 chr21    1200   970358   217   27835  1655   809     522    686
 chr22     721   554628   211   29682  1726   769     517    647
  chrM     226   208691   271   15379  1701   923     566    753
  chrX    5835  4039849   189   30215  1323   692     505    567
  chrY      23    15382   373    1034   192   669     645    722
"""

## yup. Unlike before, all chromosomes have an average of ~500 bp,
## including 21 and 22. So we basically just blocked everything.

## we'll want to do something like this below, in #3 and with our 
## data. Except that the unmapped reads should all be set to 
## "stop_receiving"


## 2) we invert, and deplete these two target sequences, sequence everything else:

human_chr_deplete21_22.toml
"""
[caller_settings]
config_name = "dna_r9.4.1_450bps_hac"
host = "ipc:///tmp/.guppy/"
port = 5555

[conditions]
reference = "/media/vol1/daniel/hostDepletion/hg38.mmi"

[conditions.0]
name = "deplete_chr_21_22"
control = false
min_chunks = 0
max_chunks = inf
targets = ["chr21", "chr22"]
single_on = "unblock"
multi_on = "unblock"
single_off = "stop_receiving"
multi_off = "stop_receiving"
no_seq = "proceed"
no_map = "proceed"
"""

conda activate readfish

## check that the client and server are talking:
python -c 'from pyguppy_client_lib.pyclient import PyGuppyClient as PGC; \
           c = PGC("ipc:///tmp/.guppy/5555", "dna_r9.4.1_450bps_fast.cfg"); \
           c.connect(); print(c)'

## yup. onto readfish
readfish targets --device MN40608 \
              --experiment-name "deplete21_22" \
              --toml /media/vol1/daniel/hostDepletion/human_chr_deplete21_22.toml \
              --log-file ru_test.log


## check the results:

TOML="/media/vol1/daniel/hostDepletion/human_chr_deplete21_22.toml"
reads="/var/lib/minknow/data/zoop8"
readfish summary $TOML $reads > readfishSummary_human_chr_deplete21_22.txt

## redirect doesn't work. anyway, cleaned up, looks like this:

contig  number      sum    min     max    std   mean  median     N50
  chr1     203  1985656    223  143583  18456   9782    1921   35106
  chr2     194  1940543    216  239229  26135  10003    2192   37848
  chr3     195  1973224    249  321947  29054  10119    1950   41776
  chr4     145  2620134    210  309287  40913  18070    2196   85360
  chr5     191  2117429    259  191101  26404  11086    1865   43932
  chr6     191  1412928    279  151998  16849   7398    1904   32483
  chr7     114  1574735    277  242490  29940  13813    3518   49974
  chr8     148  1255656    304  118447  16594   8484    1776   34932
  chr9     132  1316892    216  179598  23458   9976    1798   43623
 chr10     100  1076103    291  130248  19205  10761    2718   35462
 chr11     135  1087374    215   96666  15629   8055    1805   33647
 chr12     112  1235755    257  208411  24379  11034    1993   35706
 chr13      95   617561    220  206157  24169   6501    1028  103486
 chr14      95   975288    265  149505  25753  10266    1076   46059
 chr15      90  1057315    289  158004  27721  11748    4298   40799
 chr16      55   792690    241  241976  35456  14413    3260   62880
 chr17      71   582331    408  184443  24092   8202    1605   52554
 chr18      47   632308    380  146314  26010  13453    4060   47291
 chr19      87   570863    384  142612  18646   6562    1295   28548
 chr20      55   759285    249  156527  25388  13805    2097   40661
 chr21     903   668203    231  195532   6559    740     428     632
 chr22     366   318060    208   42955   2769    869     444    1195
  chrM      12    87633    555   16467   7057   7303    4484   16362
  chrX     132  2064894    213  321374  41516  15643    2251  134053

## seems to work, chromosome 21 and 22 reads hover around rejection
## size, the others around ~10,000
~

## 3) we block everything that aligns to the genome?

## pertinent is issue 242:
https://github.com/LooseLab/readfish/issues/242

#cp human_chr_selection.toml human_chr_depleteEntireGenome.toml
vim human_chr_depleteEntireGenome.toml

chmod 777 human_chr_depleteEntireGenome.toml

## looks like this:

#human_chr_depleteEntireGenome.toml
[caller_settings]
config_name = "dna_r9.4.1_450bps_hac"
host = "ipc:///tmp/.guppy/"
port = 5555

[conditions]
reference = "/media/vol1/daniel/hostDepletion/hg38.mmi"

[conditions.0]
name = "deplete_genome"
control = false
min_chunks = 0
max_chunks = inf
targets = []
single_on = "unblock"
multi_on = "unblock"
single_off = "unblock"
multi_off = "unblock"
no_seq = "proceed"
no_map = "stop_receiving"

## try it out:

readfish validate human_chr_depleteEntireGenome.toml

readfish targets --device MN40608 \
              --experiment-name "deplete_humanGenome" \
              --toml human_chr_depleteEntireGenome.toml \
              --log-file ru_test.log

TOML="/media/vol1/daniel/hostDepletion/human_chr_depleteEntireGenome.toml"
reads="/var/lib/minknow/data/zoop9"
readfish summary $TOML $reads  

## saving as 
readfishSummary_human_chr_depleteGenome.txt


## okay, so how do recover the reads that are not from the genome?

## seems like the way to do it is to exclude all small reads (<1000)
## align the rest to the reference


####### try on our data #####

## great, so why doesn't it work with our genome?

## first, get our combo haploid + mitochond + chloropl genome:

cd /media/vol1/daniel/hostDepletion/ourData

## can we index this?

genome=/media/vol1/daniel/spruce/Pabies_repeatsCompressed_mt_ch.fa
minimap2 -d Pabies_repeatsCompressed_mt_ch.mmi $genome

## copy of genome for lara:

sudo ln -s /media/vol1/daniel/spruce/Pabies_repeatsCompressed_mt_ch.fa \
  /media/vol2/lara/PabiesGenome_repeatsCompressed_mt_ch.fa

## we'll play with chris's bulk fast5 file that he created:

ls -lh /media/vol2/chris/Pabies_tests/bulk_fast5_files/MinION-PC_20230621_1522_FAU29445_MN40608_sequencing_run_bigger_e77dd4cd_5395a225.fast5

## it's precious. let's make a copy of it:

cp /media/vol2/chris/Pabies_tests/bulk_fast5_files/MinION-PC_20230621_1522_FAU29445_MN40608_sequencing_run_bigger_e77dd4cd_5395a225.fast5 \
/media/vol1/daniel/hostDepletion/ourData/picea.fast5

## and make a link for lara:

cd /media/vol2/chris/Pabies_tests/bulk_fast5_files/

sudo ln -s /media/vol2/chris/Pabies_tests/bulk_fast5_files/MinION-PC_20230621_1522_FAU29445_MN40608_sequencing_run_bigger_e77dd4cd_5395a225.fast5 \
  /media/vol2/lara/spruceSimulation.fast5

chmod 444 picea.fast5

## we need to change our minknow (not readfish) toml. Since we are not 
## actually sequencing, we can continue to mess with the old 106 chemistry 
## config file

vim /opt/ont/minknow/conf/package/sequencing/sequencing_MIN106_DNA.toml

## this might cause issues, because we are telling guppy that this is a 
## 10.4 cell?

## let's see

## as above, we add/substitute the line:

"""
simulation = "/media/vol1/daniel/hostDepletion/ourData/picea.fast5"
"""

## first let's try enriching for chloropolasts:

>chloroplast

# spruce_chloroplastEnrichment.toml
[caller_settings]
config_name = "dna_r10.4.1_e8.2_400bps_fast.cfg"
host = "ipc:///tmp/.guppy/"
port = 5555

[conditions]
reference = "/media/vol1/daniel/hostDepletion/ourData/Pabies_repeatsCompressed_mt_ch.mmi"

[conditions.0]
name = "enrichChloroplast"
control = false
min_chunks = 0
max_chunks = inf
targets = ["chloroplast"]
single_on = "stop_receiving"
multi_on = "stop_receiving"
single_off = "unblock"
multi_off = "unblock"
no_seq = "proceed"
no_map = "proceed"

## check this file
readfish validate spruce_chloroplastEnrichment.toml

## server/client ok? we have a new flow cell/chemistry

python -c 'from pyguppy_client_lib.pyclient import PyGuppyClient as PGC; \
           c = PGC("ipc:///tmp/.guppy/5555", "dna_r10.4.1_e8.2_400bps_fast.cfg"); \
           c.connect(); print(c)'

## nope. We are not alone:
https://community.nanoporetech.com/posts/guppy-config-files-used-by
## but of course nanopore doesn't really answer their question



## FLO-MIN114

## I think we need to restart the guppy server (and client?)

systemctl status guppyd ## config is r9.4.1...

sudo systemctl status minknow ## config is r9.4.1...

cd /opt/ont/guppy/

guppy_basecall_server --config dna_r10.4.1_e8.2_400bps_fast.cfg -p 5555 -l /tmp/guppy -x 'cuda:0'

## but I don't want to start a new server if possible to avoid. 
## I think we need to alter the minknow toml file:

cd /opt/ont/minknow/conf/package/sequencing

cp sequencing_MIN114_DNA_e8_2_400K.toml sequencing_MIN114_DNA_e8_2_400K.toml.bk

## and add in the simulation setting:
vim /opt/ont/minknow/conf/package/sequencing/sequencing_MIN114_DNA_e8_2_400K.toml

"""
simulation = "/media/vol1/daniel/hostDepletion/ourData/picea.fast5"
"""

## restarted the flowcell

## did that help?

python -c 'from pyguppy_client_lib.pyclient import PyGuppyClient as PGC; \
           c = PGC("ipc:///tmp/.guppy/5555", "dna_r10.4.1_e8.2_400bps_fast.cfg"); \
           c.connect(); print(c)'

## nope
## can't get guppy to take the new chemistry...ugh. 

ls -l /tmp/.guppy/5555
sudo chmod 775 /tmp/.guppy/5555

readfish targets --device MN40608 \
              --experiment-name "enrichChloroplast" \
              --toml spruce_chloroplastEnrichment.toml \
              --log-file chloro_test.log


cp /media/vol1/daniel/hostDepletion/human_chr_selection.toml \
/media/vol1/daniel/hostDepletion/ourData/
mv human_chr_selection.toml bigGenome_depletion.toml 

sudo systemctl restart guppyd

sudo systemctl status guppyd


######### resetting guppy with a new config file #####

## as before, the gringer lab has some hints about this:

https://gringer.gitlab.io/presentation-notes/2021/10/08/gpu-calling-in-minknow/#verifying-the-configuration-change-1

## ah, here is the description of the guppy settings
cat /etc/systemd/system/guppyd.service

cd /etc/systemd/system/

## this is a link to:
ls /lib/systemd/system/guppyd.service

## make a backup and link to backup:

sudo cp /lib/systemd/system/guppyd.service /lib/systemd/system/guppyd.service.bk

sudo ln -s /lib/systemd/system/guppyd.service.bk /etc/systemd/system/guppyd.service.bk

less /etc/systemd/system/guppyd.service

## try a manual edit?


## we want to use the r9 setting for our simulations, but an r10 cfg for our 
sudo vim /etc/systemd/system/guppyd.service

## changed the following line:
ExecStart=/opt/ont/guppy/bin/guppy_basecall_server --log_path /var/log/guppy --config dna_r9.4.1_450bps_fast.cfg --num_callers 1 --port /tmp/.guppy/5555 --ipc_threads 3 --device cuda:all
## to:
ExecStart=/opt/ont/guppy/bin/guppy_basecall_server --log_path /var/log/guppy --config dna_r10.4.1_e8.2_400bps_fast.cfg --num_callers 1 --port /tmp/.guppy/5555 --ipc_threads 3 --device cuda:all

## restart:

sudo systemctl restart guppyd ## didn't work. try:

systemctl daemon-reload

sudo systemctl status guppyd ## reports that it is using the new device, r10.4

## will it work with our new data now?

## always have to check the tcp socket permissions
ls -l /tmp/.guppy/5555
sudo chmod 775 /tmp/.guppy/5555

python -c 'from pyguppy_client_lib.pyclient import PyGuppyClient as PGC; \
           c = PGC("ipc:///tmp/.guppy/5555", "dna_r10.4.1_e8.2_400bps_fast.cfg"); \
           c.connect(); print(c)'

## works now, how about the readfish command itself?

cd /media/vol1/daniel/hostDepletion/ourData

readfish targets --device MN40608 \
              --experiment-name "enrichChloroplast" \
              --toml spruce_chloroplastEnrichment.toml \
              --log-file chloro_test.log

less chloro_test.log

## and its running. Let that go for a while...

## the report is probably really long:

TOML="spruce_chloroplastEnrichment.toml"
reads="/var/lib/minknow/data/spruceZoop4"
readfish summary $TOML $reads  

## output is too big, but luckily chloroplast
## contig is at the bottom, here is a piece of 
## it:

 contig  number      sum    min     max    std   mean  median     N50
 MA_9931298       2    5064  1223   3841   1851   2532    2532   3841
 MA_9932586       5    3231   322   1407    447    646     526    648
 MA_9934715       2     993   465    528     45    496     496    528
 MA_9940839       3     924   282    353     39    308     289    289
 MA_9943563       7   10663   489   4001   1214   1523    1172   2041
 MA_9944826       3    1045   346    351      3    348     348    348
 MA_9944965       2     740   370    370      0    370     370    370
   MA_99477       4    2055   347    728    194    514     490    629
 MA_9949434       3    2133   327   1232    468    711     574   1232
 MA_9952592       2    1717   704   1013    218    858     858   1013
 MA_9952612       2     702   312    390     55    351     351    390
 MA_9954524       3    1747   541    606     36    582     600    600
 MA_9957133       4    1626   364    434     31    406     414    426
 MA_9958369       3    1041   267    488    122    347     286    286
   MA_99587       5    1966   245    755    211    393     323    390
 MA_9960185       6    3948   441   1052    215    658     632    677
 MA_9960987       5    4064   321   2113    740    813     565   2113
  MA_996288       8    2982   311    496     71    373     352    353
 MA_9963269       4    2408   421    738    134    602     624    656
 MA_9965332      15   29081   298   7890   2271   1939     787   4391
 MA_9966395      51   52399   278   4916    736   1027     827   1203
 MA_9967845       2    1147   375    772    281    574     574    772
   MA_99688       2    3461   351   3110   1951   1730    1730   3110
 MA_9970702       2    2682  1073   1609    379   1341    1341   1609
 MA_9970721       2    2739   788   1951    822   1370    1370   1951
  MA_997147       2     716   320    396     54    358     358    396
 MA_9972548       2    1174   377    797    297    587     587    797
 MA_9975192       8    4907   344    858    221    613     703    759
 MA_9979455       2     925   364    561    139    462     462    561
 MA_9980845       2     816   307    509    143    408     408    509
  MA_998108       3    1503   472    523     26    501     508    508
  MA_998135       2    1241   365    876    361    620     620    876
   MA_99829       3    2977   410   1871    774    992     696   1871
  MA_998349       3    9066   240   8145   4442   3022     681   8145
  MA_998504       2    1079   372    707    237    540     540    707
 MA_9994173       2    2351   427   1924   1059   1176    1176   1924
   MA_99942      10   10426   312   2082    602   1043     924   1389
 MA_9997692       2    1028   348    680    235    514     514    680
 MA_9997874      10    3797   223   1027    239    380     289    358
   MA_99981       2    2982  1464   1518     38   1491    1491   1518
 MA_9998159       3    2061   316   1256    500    687     489   1256
 MA_9998442       3    1208   318    479     81    403     411    411
 MA_9999734       3    1197   323    450     67    399     424    424
chloroplast     151  625899   249  14565   2979   4145    3546   5652

## looks pretty good. The chloroplast have a much greater sum of BP,
## longer median and mean. 

#### try entire genome depletion ####

## this time let's limit chunks to 3?

## the base documentation is here
https://github.com/LooseLab/readfish/blob/dev_staging/TOML.md#local-basecalling
## the same issue above is useful here:
https://github.com/LooseLab/readfish/issues/242

## try the 
## "bigGenome_depletion.toml":
[caller_settings]
config_name = "dna_r10.4.1_e8.2_400bps_fast.cfg"
host = "ipc:///tmp/.guppy/"
port = 5555

[conditions]
reference = "/media/vol1/daniel/hostDepletion/ourData/Pabies_repeatsCompressed_mt_ch.mmi"

[conditions.0]
name = "depleteSpruceHost"
control = false
min_chunks = 0
max_chunks = 3
targets = []
single_on = "unblock"
multi_on = "unblock"
single_off = "unblock"
multi_off = "unblock"
no_seq = "proceed"
no_map = "stop_receiving"


## try it out:
readfish validate bigGenome_depletion.toml

readfish targets --device MN40608 \
              --experiment-name "depleteSpruceGenome" \
              --toml bigGenome_depletion.toml \
              --log-file depleteSpruce_test.log


## looks like it is working well, the mapping times 
## are really low, ~0.13s

TOML="spruce_chloroplastEnrichment.toml"
reads="/var/lib/minknow/data/spruceZoop4"
readfish summary $TOML $reads  


######## processing, post readfish #########

## I see several ways forward here. 

## the most important info is that the short reads 
## mostly rejected reads. 

## also they are not that useful for 
## metagenomes. 

## so it makes sense to filter them out, right away,
## and see if enough information remains for 
## metagenomes and MAGs. 

## I guess we could run a metagenome assembler on it 
## right away. 

## and do some gene prediction, send it off to 
## kegg

## to report nice results, we need to do both. Means 
## a full metagenome/MAG pipeline. 
## a quality check, etc. 
 
## first step - filter reads <1000 bp

## we have lots of fasta files, here:

ls /var/lib/minknow/data/spruceZoop5/no_sample/20230630_1147_MN40608_spruceZoop5_f5ee253a/fastq_pass/

ls -lh /var/lib/minknow/data/spruceZoop5/no_sample/20230630_1147_MN40608_spruceZoop5_f5ee253a/fastq_pass/

cd /media/vol1/daniel/hostDepletion/ourData/bigGenome_depletion_data

cp /var/lib/minknow/data/spruceZoop5/no_sample/20230630_1147_MN40608_spruceZoop5_f5ee253a/fastq_pass/*fastq.gz .

gunzip *

cat * > bigGenome.fastq

wc -l bigGenome.fastq ## 128000/4 = 32000 reads

grep -c "^@" bigGenome.fastq ## 32001

## is there a seqtk solution?
seqtk seq -L 1000 bigGenome.fastq > lessThan1000.fastq

## get a fastqc report on this

conda activate

conda install -c bioconda fastqc

rm -r qc/
mkdir qc/
fastqc -t 8 -o qc --extract  lessThan1000.fastq

## get it local

rm -r /home/daniel/Documents/projects/fichtelgebirge_project/spruceGenome/dataFromHostDep/qc
file=/media/vol1/daniel/hostDepletion/ourData/bigGenome_depletion_data/qc/
dest=/home/daniel/Documents/projects/fichtelgebirge_project/spruceGenome/dataFromHostDep/
scp -r -i ~/.ssh/id_ed25519 test@132.180.112.115:$file $dest

cd /home/daniel/Documents/projects/fichtelgebirge_project/spruceGenome/dataFromHostDep/qc

firefox lessThan1000_fastqc.html ## huh, actually looks pretty good, an average quality per read ~18. 


python3 
import math
## convert to probability (http://drive5.com/usearch/manual/quality_score.html)

10**(-18/10) ## something like a 1.5% error rate, or 98.5% correct reads/bp

## not bad.

## it might be good to align these reads against the host genome, and see what is left 
## standing...which genome should we use?

## let's use the full genome, with repeats, plus mitochondria assembly, plus chloroplast:

cat Pabies-haploid.fa Picea_abies_mtDNA_assembly.fa Pabies01-chloroplast.fa > Pabies-haploid_withOrganelles_raw.fa

seqtk seq -l 60 Pabies-haploid_withOrganelles_raw.fa > Pabies-haploid_withOrganelles.fa


minimap2 -a ref.fa query.fq > alignment.sam

minimap2 -ax map-ont ref.fa ont-reads.fq > aln.sam 

minimap2 -ax map-ont ref.fa ont-reads.fq > aln.sam 

genome=/media/vol1/daniel/spruce/Pabies-haploid_withOrganelles.fa
reads=/media/vol1/daniel/hostDepletion/ourData/bigGenome_depletion_data/lessThan1000.fastq

minimap2 -t 4 -I 100g  -ax map-ont $genome $reads > bigReadsAlign2Spruce.sam  ## used up to 47 gig RAM. Wow. need de.NBI instance 

## now we want just those that didn't align to host, as a start.
## later we may not want to do this, may result in lower information 
## about primary metabolism...

conda create -n samtools -c bioconda samtools
## for some reason, had to do a reinstall immediately to a lower version
conda install -c bioconda samtools=1.9 --force-reinstall

conda activate samtools 

samtools view 

samtools fastq -f4 bigReadsAlign2Spruce.sam > unalignedSpruceReads.fastq

wc -l unalignedSpruceReads.fastq ## 2412, so only 600 reads, many of which look like junk...

## if we assume 600 reads out of 32000 original reads are maybe microbial ~1.8%, seems reasonable
## then 

wc -l lessThan1000.fastq ## 73180 / 4 = 18295 reads after exclusion of the unblocked reads. 

## 600 / 73180 = ~3.2% of reads. So this doesn't quite double the microbial reads (maybe) in this set. 

## things are rosier if we judge by basepairs, not reads, because the reads are so long.

## on the other hand, aligned again to host might cause a lot of less-than-great alignments
## pulling away from our microbial reads artificially

## so another way to gauge the potential amount of microbial information in this data set is to 
## align to known microbial sequences rather than to eukaryotic host and subtracting

## and 1000 bp is too harsh of a cutoff. In this dataset, almost all reads are unblocked 
## by 600 bp. Probably because we  

## interesting, at least some of these are bacterial, 
## like @9b04d8a6-be55-4753-8bae-311b90f96137, blasts to plasmid
## and @c1654718-897f-4269-a511-ae62cdd2b380, also plasmid...hmmm
## and @b5106860-7789-4d7d-a1b7-3af28dc88018, maybe also a plasmid, or just part of ecoli genome...
## did we enrich for plasmids?

## anyway, we need to automate this. Our local computer cannot handle even this little dataset. 
://ds.aai.lifescience-ri.eu/ds/?entityID=https%3A%2F%2Fproxy.aai.lifescience-ri.eu%2Fmetadata%2Fbackend.xml&return=https%3A%2F%2Fproxy.aai.lifescience-ri.eu%2Fsaml2sp%2Fdisco# # reminds me we need to request a de.nbi instance, btw...probably today.
## denbi instance quick.
## done.

## the simulation is still running - is there some way to know how many reads are in the 
## 

ls -lh /media/vol2/chris/Pabies_tests/bulk_fast5_files/MinION-PC_20230621_1522_FAU29445_MN40608_sequencing_run_bigger_e77dd4cd_5395a225.fast5

## I think this is from this run:
cd /var/lib/minknow/data/Pabies_bulk_fast5/bigger/20230621_1517_MN40608_FAU29445_e77dd4cd
du -sh ## 2.1 G

## he also has this run:
cd /var/lib/minknow/data/Pabies_bulk_fast5/Version_1/20230621_1347_MN40608_FAU29445_a01d2181
du -sh ## 650 M

cd /var/lib/minknow/data/Pabies_bulk_fast5/

## not sure 
## this is only 112M of passed fastq sequence data. That can't possibly be what I'm simulating with...
## I'll have to ask Chris

## anyway, stop the simulated run for now. We are already at the edge of computational resources for alignments, etc. 

## generally good news, looks like our setup can handle the large genome, at least in the simulations. 

## the plan:

## run the above pipeline for "full" dataset, then go further by 
## downloading some kind of prokaryote database from NCBI

## data is here:

cd /var/lib/minknow/data/spruceZoop5/no_sample/20230630_1147_MN40608_spruceZoop5_f5ee253a/fastq_pass/

cp /var/lib/minknow/data/spruceZoop5/no_sample/20230630_1147_MN40608_spruceZoop5_f5ee253a/fastq_pass/*fastq.gz ./

cd /media/vol1/daniel/hostDepletion/ourData/bigGenome_depletion_data/bigDataRedo

gunzip *fastq.gz

cat *.fastq > comboSpruceZoop5.fastq 

## let's go down to 500bp, the read distribution indicates this is a pretty 
## good cutoff for the readfish rejection threshold

seqtk seq -L 500 comboSpruceZoop5.fastq > comboSpruceZoop5_onlyBigReads.fastq

grep -c "^@" comboSpruceZoop5.fastq  ## 108,743 reads
grep -c "^@" comboSpruceZoop5_onlyBigReads.fastq  ## 68,902 reads

## fastqc

conda activate 

mkdir qcBig/
fastqc -t 8 -o qcBig --extract comboSpruceZoop5_onlyBigReads.fastq

mkdir qcSmall/

fastqc -t 8 -o qcSmall --extract comboSpruceZoop5.fastq

#file=/media/vol1/daniel/hostDepletion/ourData/bigGenome_depletion_data/bigDataRedo/qcSmall/

file=/media/vol1/daniel/hostDepletion/ourData/bigGenome_depletion_data/bigDataRedo/qcBig/

dest=/home/daniel/Documents/projects/fichtelgebirge_project/spruceGenome/dataFromHostDep/qc/

scp -r -i ~/.ssh/id_ed25519 test@132.180.112.115:$file $dest

## run these through same pipeline as above  

genome=/media/vol1/daniel/spruce/Pabies-haploid_withOrganelles.fa
reads=/media/vol1/daniel/hostDepletion/ourData/bigGenome_depletion_data/bigDataRedo/comboSpruceZoop5_onlyBigReads.fastq
minimap2 -t 4 -I 100g  -ax map-ont $genome $reads > bigReadsAlign2Spruce.sam  ## too memory hungry, process killed

## can we put guppy on pause for a minute?
cd /lib/systemd/system/

#sudo cp /lib/systemd/system/guppyd.service /lib/systemd/system/guppyd.service.bk

sudo vim /lib/systemd/system/guppyd.service 

## leaving for a while. Clean up the minknow 114 flowcell sequencing toml for Chris, he may need it

vim /opt/ont/minknow/conf/package/sequencing/sequencing_MIN114_DNA_e8_2_400K.toml
## commented out line 179 in that file

##### 22.7.23 #####

## we have a new experiment running, with host depletion running

## let's check on it, and see if it seems like we should keep it
## running 

## data is here, on lab comp

ls /var/lib/minknow/data/repeatingDansStuff1/21_7_23/20230721_1214_MN40608_FAS81869_d4801a32

cd /var/lib/minknow/data/repeatingDansStuff1/21_7_23/20230721_1214_MN40608_FAS81869_d4801a32

wc -l unblocked_read_ids.txt ## 367603 reads blocked

## manually check a few. still on nanoComp

FAS81869_pass_d4801a32_55579c61_47.fastq.gz

mkdir -p /media/vol1/daniel/spruce/hostDepletion_7.22.23

cp FAS81869_pass_d4801a32_55579c61_47.fastq.gz /media/vol1/daniel/spruce/hostDepletion_7.22.23/

cd /media/vol1/daniel/spruce/hostDepletion_7.22.23/

gunzip FAS81869_pass_d4801a32_55579c61_47.fastq.gz

## get rid of the long reads:

seqtk seq -L 500 FAS81869_pass_d4801a32_55579c61_47.fastq > FAS81869_pass_d4801a32_55579c61_47_onlyBigReads.fastq

grep -c "^@" FAS81869_pass_d4801a32_55579c61_47.fastq ## 4000
grep -c "^@" FAS81869_pass_d4801a32_55579c61_47_onlyBigReads.fastq ## 2819

less FAS81869_pass_d4801a32_55579c61_47_onlyBigReads.fastq 

## make some backups...

## the good stuff (passed reads) are already compressed, here:

cd /var/lib/minknow/data/repeatingDansStuff1/21_7_23/20230721_1214_MN40608_FAS81869_d4801a32

tar cvf hostDepletion_7.22.23.tar ./fastq_pass

## now put this on home computer and de.nbi computer.
## would put this on officeDesktop but it's off. 

path2get="/var/lib/minknow/data/repeatingDansStuff1/21_7_23/20230721_1214_MN40608_FAS81869_d4801a32/hostDepletion_7.22.23.tar"
path2put="/home/daniel/Documents/projects/fichtelgebirge_project/spruceGenome/depletion2big4github/spruceDepletion_7.22.23/"
scp -i /home/daniel/.ssh/./id_ed25519 test@132.180.112.115:$path2get $path2put

## get it on denbi:
path2get="/home/daniel/Documents/projects/fichtelgebirge_project/spruceGenome/depletion2big4github/spruceDepletion_7.22.23/hostDepletion_7.22.23.tar"
path2put="/vol/piceaNanopore/dan/"
scp -P 30419 -i /home/daniel/.ssh/./id_ed25519 $path2get ubuntu@129.70.51.6:$path2put

## get it on the officeComp that lara is using:
path2get="/home/daniel/Documents/projects/fichtelgebirge_project/spruceGenome/depletion2big4github/spruceDepletion_7.22.23/hostDepletion_7.22.23.tar"
path2put="/home/daniel/Documents/backUpSpruceHostDepletion"
scp -i /home/daniel/.ssh/./id_ed25519 $path2get daniel@132.180.112.24:$path2put
## that broke...fix later

## ok, backed up. Now, working on de.NBI, we're going to 
## need to get files between the denbi and lab computers

ssh-keygen -t rsa -f lab2denbi

cd /vol/piceaNanopore/dan

tar xvkf hostDepletion_7.22.23.tar

## we'll do two pipelines. In one, we'll try to "subtract" host reads 
## with an alignment. In the second, we'll just go straight to assembly, 
## hoping that the host will come out as just one more MAG. 

## is there an easy way to use the list of the unblocked reads 
## to decide which reads that were rejected. 

## on the lab nanopore computer, these unblocked (rejected) reads:
ls /var/lib/minknow/data/repeatingDansStuff1/21_7_23/20230721_1214_MN40608_FAS81869_d4801a32/unblocked_read_ids.txt

## let's put this on the denbi comp, from lab comp:
path2get=/var/lib/minknow/data/repeatingDansStuff1/21_7_23/20230721_1214_MN40608_FAS81869_d4801a32/unblocked_read_ids.txt
path2put="/vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/"
scp -P 30419 -i /home/test/.ssh/lab2denbi $path2get ubuntu@129.70.51.6:$path2put

## can we use this somehow to select the reads we need?

## on denbi, maybe use seqkit for this:

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/fastq_pass

gunzip -k *

## actually, do that with pigz 
pigz -p10 -dk * 

## make one big file:

cat *fastq > allChrisHostDepletionTrial_pass.fastq

wc -l allChrisHostDepletionTrial_pass.fastq ## 6657908, or 1,664,477 reads

conda create -n seqkit -c bioconda seqkit

conda activate seqkit

## try a toy file`

head unblocked_read_ids.txt > unblockIds30.txt

allPassed="/vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/fastq_pass/allChrisHostDepletionTrial_pass.fastq"

head -n 1 $allPassed 

echo "22374732-69a0" > id.txt

seqkit grep $allPassed -f id.txt -o testing.fa

seqkit grep $allPassed -p "22374732" -o testing.fa

seqkit grep $allPassed -irp "22374732" 

seqkit grep $allPassed -irnp "22374732" 

seqkit grep $allPassed -rn -f unblockIds30.txt #-o testing.fa

## extend this to the full unblocked read list. 
## all unblocked reads are rejected 

seqkit grep $allPassed -vrnj 10 -f unblocked_read_ids.txt -o testing.fa

## takes forever. try nohup, up the cores

nohup seqkit grep $allPassed -vrnj 20 -f unblocked_read_ids.txt -o allChrisHostDepletionTrial_noShorts.fastq

grep -c "^@" allChrisHostDepletionTrial_noShorts.fastq

/vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData

ssh -p 30419 -i /home/daniel/.ssh/./id_ed25519 ubuntu@129.70.51.6 \
  "grep -c "^@" /vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/allChrisHostDepletionTrial_noShorts.fastq"

grep -c "^@" /vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/allChrisHostDepletionTrial_noShorts.fastq

## there are 1,664,548 reads in the passed reads. 
## there are 617,842 unblocked reads. 
## so there should be ~1 million reads after removing the short reads
## that is taking a long time. let that run overnight,  



path2get=/media/vol1/daniel/spruce/Pabies-haploid_withOrganelles.fa
path2put="/vol/piceaNanopore/dan/chrisHostDepletionTrial/spruceRefGenome/"
scp -P 30419 -i /home/test/.ssh/lab2denbi $path2get ubuntu@129.70.51.6:$path2put

## next day: that is taking forever! one overnight gives us ~100000 reads.
##  we may need to shut that down  just curious, if we simply remove all 
## short reads, does this approach the right numbers? knowing that we 
## should have ~1 million reads after removal of unblocked reads?
  
allPassed="/vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/fastq_pass/allChrisHostDepletionTrial_pass.fastq"
seqtk seq -L 500 $allPassed > allChrisHostDepletionTrial_biggerThan500.fastq

grep -c "^@" allChrisHostDepletionTrial_biggerThan500.fastq ## 1211902
## about 200,000 too many, try a stricter cutoff:

seqtk seq -L 600 $allPassed > allChrisHostDepletionTrial_biggerThan600.fastq
grep -c "^@" allChrisHostDepletionTrial_biggerThan600.fastq ## 1180127, closer

seqtk seq -L 700 $allPassed > allChrisHostDepletionTrial_biggerThan700.fastq
grep -c "^@" allChrisHostDepletionTrial_biggerThan700.fastq ## 1162100, pretty much the same. weird.
## let's keep the 600 bp read length minimum, keep going. 

## two days later, seqkit is still going. 
## can seqtk do it better?

## we need the names of all the reads in the raw nanopore data:

sed -n '1~4p' fastq_pass/allChrisHostDepletionTrial_pass.fastq | \
cut -f 1 -d " " | \
sed "s/^@//" > allChrisHostDepletionTrial_pass_names.txt

wc -l allChrisHostDepletionTrial_pass_names.txt               ## 1664477
wc -l fastq_pass/allChrisHostDepletionTrial_pass.fastq        ## 1664477 (x4)
wc -l unblocked_read_ids.txt                                  ##  617842

## 1664477 - 617842 = 1046635, should be 1,046,635 reads after we remove unblocked reads

## take out the names of the unblocked reads from the list of all read names:

sort <(cat allChrisHostDepletionTrial_pass_names.txt unblocked_read_ids.txt) > comboNames.txt
uniq -u comboNames.txt > allChrisHostDepletionTrial_noShorts_names.txt

wc -l allChrisHostDepletionTrial_noShorts_names.txt ## 1319301, that didn't work.

## I guess some of these unblocked read ids weren't included in the final
## passed reads by minknow. Will this offend seqtk if there are unmatched 
## names in the list?:

seqtk subseq fastq_pass/allChrisHostDepletionTrial_pass.fastq \
 allChrisHostDepletionTrial_noShorts_names.txt > allChrisHostDepletionTrial_noShorts.fastq

wc -l allChrisHostDepletionTrial_noShorts.fastq ## 5005332 / 4 = 1251333
## 1,251,333 reads after we get rid of unblocked reads. Not to different from:
## 1,180,127 reads when we remove reads < 600 bp long, see below

## files sizes:
## <600 bp file size = 11348659574
## reads-manually-removed file size = 11420259495

11348659574 - 11420259495 = -71599921

## ~70 megabytes difference in file size. Is it worth redoing 
## the pipeline below with this file?
## soon but not yet.

###########

## for now build the pipeline with crude, <600 bp reads removed file:

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/alignment

genome="/vol/piceaNanopore/dan/chrisHostDepletionTrial/spruceRefGenome/Pabies-haploid_withOrganelles.fa"
reads="/vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/allChrisHostDepletionTrial_biggerThan600.fastq"
#reads="/vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/allChrisHostDepletionTrial_noShorts.fastq"
#minimap2 -t 20 -ax map-ont $genome $reads > bigReadsAlign2Spruce.sam  
## trying to debug with better settings, see below:
minimap2 -R "@RG\\tID:spruceDep\\tSM:spruceDep" -I12g -t 20 -ax map-ont $genome $reads > bigReadsAlign2Spruce.sam  

## what is our range of mapQ scores...  

## I think we need picard/gatk:

conda update -n base -c defaults conda

conda create -n gatk -c bioconda gatk4 picard 

conda create -n samtools -c bioconda "samtools>=1.15"

conda activate gatk

conda install -c bioconda samtools ## for some reason, the version I can 
## get with bioconda is old. use ubuntu rep instead (Apt)

conda remove -n gatk --all

## had to add an old ssl library for this??
## needed an old repo added to apt sources.list:
deb http://security.ubuntu.com/ubuntu xenial-security main
## then install was okay
sudo apt install libssl1.0.0

## https://gatk.broadinstitute.org/hc/en-us/articles/13832754678171-QualityScoreDistribution-Picard-

picard QualityScoreDistribution \
  I=bigReadsAlign2Spruce.sam \
  O=mapQdist_christDep.txt \
  CHART=mapQdist_christDep.pdf


## and of course something is off with our sam file

## following: https://gatk.broadinstitute.org/hc/en-us/articles/360035891231-Errors-in-SAM-or-BAM-files-can-be-diagnosed-with-ValidateSamFile

## using new picard syntax:
picard ValidateSamFile -I bigReadsAlign2Spruce.sam -MODE SUMMARY

## doesn't work yet. try old way
picard ValidateSamFile \
      I=bigReadsAlign2Spruce.sam \
      MODE=SUMMARY

########################################################################
#### HISTOGRAM    java.lang.String
##Error Type      Count
##ERROR:MISSING_READ_GROUP        1
##ERROR:MISSING_SEQUENCE_DICTIONARY       37027303
##WARNING:QUALITY_NOT_STORED      52
##WARNING:RECORD_MISSING_READ_GROUP       37229909
########################################################################

picard ValidateSamFile \
      I=bigReadsAlign2Spruce.sam \
      IGNORE_WARNINGS=true \
      MODE=VERBOSE

## this tells us that basically all alignments are missing a sequence dictionary...

##############################################################################################
# ERROR: Record 71, Read name cebbe9b3-e56e-4479-8c15-5b86cc621719, Empty sequence dictionary.
# ERROR: Record 72, Read name cebbe9b3-e56e-4479-8c15-5b86cc621719, Empty sequence dictionary.
##############################################################################################

## so following: 
## https://gatk.broadinstitute.org/hc/en-us/articles/360035531652-FASTA-Reference-genome-format
## we need both a gatk fasta dictionary file, and a fasta index

## gatk fasta dictionary

genome="/vol/piceaNanopore/dan/chrisHostDepletionTrial/spruceRefGenome/Pabies-haploid_withOrganelles.fa"

gatk CreateSequenceDictionary -R $genome -O Pabies-haploid_withOrganelles.dict

less bigReadsAlign2Spruce.sam

## fasta index 
samtools faidx $genome -o Pabies-haploid_withOrganelles.fai

## both of these put the file right next to the ref genome in:

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/spruceRefGenome

conda activate gatk

picard ValidateSamFile \
      I=bigReadsAlign2Spruce.sam \
      MODE=SUMMARY

picard ValidateSamFile \
      I=bigReadsAlign2Spruce.sam \
      IGNORE_WARNINGS=true \
      MODE=VERBOSE

picard AddOrReplaceReadGroups

picard AddOrReplaceReadGroups \
    I=$genome \
    O="Pabies-haploid_withOrganelles.bam" \
    RGID=1 \
    RGLB=chrisDepletion \
    RGPU=55579c61d43f72e259ebddaedd7434c488f47e6a \
    RGPL=nanopore \
    RGSM=spruce \
    CREATE_INDEX=True

## it's not finding dictionaries...do we have to be in same directory

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData

/vol/piceaNanopore/dan/chrisHostDepletionTrial/spruceRefGenome

## ugh, screw gatk/picard

## first step, get totally unmapped reads - how many are there?

## samtools needs proper headers. Minimap2 doesn't make them, 
## unless you give it enough memory to swallow the whole 
## reference genome at once, with --I12g
## see: 
## https://github.com/lh3/minimap2/blob/master/FAQ.md#3-the-output-sam-doesnt-have-a-header

samtools view bigReadsAlign2Spruce.sam \
  --threads 20 \
  -q "5" \
  -U "poorHostMatches.sam" \
  -h \
  -O SAM \
  -o "goodHostMatches.sam"

## convert these to poor matches back to fastq:
samtools fastq poorHostMatches.sam > poorHostMatches.fastq
## to get the totally unalign reads:
samtools fastq -f 4 bigReadsAlign2Spruce.sam > hostNonMatches.fastq 

grep -c "^@" poorHostMatches.fastq ## 257,671 reads...
grep -c  "^@" hostNonMatches.fastq ## 55,466 reads...

## let's go with just the poorHostMatches, and the raw reads

## goal for tonight - get metaflye going on at least one of these

## look at the raw reads with fastqc 

conda create -n fastqc -c bioconda fastqc

conda activate fastqc

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial

fastqc -o /vol/piceaNanopore/dan/chrisHostDepletionTrial/fastqcOut/poorHostMatches/ \
       --memory 1024 \
       -t 20 \
    /vol/piceaNanopore/dan/chrisHostDepletionTrial/alignment/poorHostMatches.sam

fastqc -o /vol/piceaNanopore/dan/chrisHostDepletionTrial/fastqcOut/allReads \
       --memory 1024 \
       -t 20 \
  /vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/fastq_pass/allChrisHostDepletionTrial_pass.fastq &> allChrisFastqc.log

## let's get this local and look at it

path2get=/vol/piceaNanopore/dan/chrisHostDepletionTrial/fastqcOut/
scp -rP 30419 ubuntu@129.70.51.6:$path2get .

## there are fragments much smaller than our reads
## The alignment is giving only fragments back out of the 
## sam file. We don't want the actual alignments, 
## we just want every fragment that had some alignment to
## host.  

## back on denbi


## for instance let's find this read in it's various forms:

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial

#seqName="a102de22-3e5a-406a-835c-bd58d58052bd"

seqName="01c5b5f5-d3e9-4c3f-8aa3-308e008f5328"

echo "#####################################################################" > randomReadCheckAlignment.txt && \
echo "########### allChrisHostDepletionTrial_biggerThan600.fastq ##########" >> randomReadCheckAlignment.txt && \
grep -A 1 $seqName nanoporeRunData/allChrisHostDepletionTrial_biggerThan600.fastq >> randomReadCheckAlignment.txt && \
echo "" >> randomReadCheckAlignment.txt && \
echo "#####################################################################" >> randomReadCheckAlignment.txt && \
echo "#################### bigReadsAlign2Spruce.sam #######################" >> randomReadCheckAlignment.txt && \
grep $seqName alignment/bigReadsAlign2Spruce.sam   >> randomReadCheckAlignment.txt
echo "" >> randomReadCheckAlignment.txt && \
echo "#####################################################################" >> randomReadCheckAlignment.txt && \
echo "######################  goodHostMatches.sam  ########################" >> randomReadCheckAlignment.txt && \
grep $seqName alignment/goodHostMatches.sam   >> randomReadCheckAlignment.txt
echo "" >> randomReadCheckAlignment.txt && \
echo "#####################################################################" >> randomReadCheckAlignment.txt && \
echo "#####################   poorHostMatches.sam   #######################" >> randomReadCheckAlignment.txt && \
grep $seqName alignment/poorHostMatches.sam   >> randomReadCheckAlignment.txt

less randomReadCheckAlignment.txt

## ugh. losing track here. We want a way to remove reads that align well to 
## to the spruce genome. Perhaps a better way to do this is to set a really
## high threshold for matches to spruce genome, and collect the names of 
## these sequences

## the first part is easy:

samtools view bigReadsAlign2Spruce.sam \
  --threads 20 \
  -q "30" \
  -U "poorHostMatches.sam" \
  -h \
  -O SAM \
  -o "goodHostMatches.sam"

## the second part is not. How do we collect the names of the sequences
## with good matches? 

## /^@RG gets us to the alignments, past the really long header

samtools view -@ 20 goodHostMatches.sam | head

samtools view -@ 20 goodHostMatches.sam | cut -f1 | sort | uniq > goodHostMatches_readNames.txt

wc -l goodHostMatches_readNames.txt ## 1,026,367, out of maybe 1,180,000. Hmm...that's most. 

## oh well. Try to get rid of them, see if seqtk works faster than our
## grep solution with seqkit

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData

echo "22374732-69a0-477f-b5de-1d7fbfba33fa" > name.lst
echo "01c5b5f5-d3e9-4c3f-8aa3-308e008f5328" >> name.lst
seqtk subseq fastq_pass/allChrisHostDepletionTrial_pass.fastq name.lst > out.fq
## seems to work

## to do this we need to subtract the goodhostmatches from the larger
## pool of unblocked reads. 


cd /vol/piceaNanopore/dan/chrisHostDepletionTrial

allChrisHostDepletionTrial_biggerThan600.fastq

alignment/goodHostMatches_readNames.txt

## the names of our fastq file should be:
sed -n '1~4p' allChrisHostDepletionTrial_biggerThan600.fastq | \
cut -f 1 -d " " | \
sed "s/^@//" > allChrisHostDepletionTrial_biggerThan600_names.txt

allChrisHostDepletionTrial_biggerThan600_names.txt
goodHostMatches_readNames.txt 

sort <(cat goodHostMatches_readNames.txt allChrisHostDepletionTrial_biggerThan600_names.txt) > comboNames.txt
uniq -u comboNames.txt > nonHostReadNames.txt

## use this to subset to just reads of interest:
seqtk subseq allChrisHostDepletionTrial_biggerThan600.fastq nonHostReadNames.txt > nonHostReads.fastq
## whoah that was fast. 

wc -l goodHostMatches_readNames.txt                      ## 1026367
wc -l allChrisHostDepletionTrial_biggerThan600_names.txt ## 1180067
wc -l comboNames.txt                                     ## 2206434 
wc -l <(uniq comboNames.txt)                             ## 1180067
wc -l <(uniq -u comboNames.txt)                          ## 153700
wc -l nonHostReadNames.txt                               ## 153700
wc -l nonHostReads.fastq                                 ## 614800 / 4 = 153700

## so we theoretically end up with ~153,700 reads that are not well aligned to host. 

## run fastqc on them and try an assembly

mkdir /vol/piceaNanopore/dan/chrisHostDepletionTrial/fastqcOut/nonHostReads

fastqc -o /vol/piceaNanopore/dan/chrisHostDepletionTrial/fastqcOut/nonHostReads/ \
       --memory 1024 \
       -t 20 \
    /vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/nonHostReads.fastq &> fastqc.log &

path2get=/vol/piceaNanopore/dan/chrisHostDepletionTrial/fastqcOut/nonHostReads/ 
scp -rP 30419 ubuntu@129.70.51.6:$path2get 

## really need to update my nanopore qc.
## try nanopack tools:

conda install -c bioconda nanoqc

## they look ok. try an assembly:

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial

conda activate flye

reads=/vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/nonHostReads.fastq
outdir=/vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/nonHostReadAssembly

nohup flye --meta \
    --nano-raw $reads \
    --threads 25 \
    --out-dir $outdir \
    &> noHostAssembly.log &

## quick, 10 min or so, maybe less
## that looks weird. some of the host definitely slipped through. Do gene predictions on it tomorrow. 

## will flye accept the full fastq, with a lot of host reads?


reads=/vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/allChrisHostDepletionTrial_noShorts.fastq
outdir=/vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/hostReduced/

nohup flye --meta \
    --nano-raw $reads \
    --threads 25 \
    --out-dir $outdir \
    &> reducedHostAssembly.log &

## looks like that took ~2 hours.
## results are interesting, can't immediately dismiss them at least,
## a few circular genomes reported, some weird initial blasts, etc.

## so what now? 

## gene prediction, send off to KEGG. And try binning, you never know. 

conda activate prodigal


cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/hostReduced/

hostReducedAssembly=/vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/hostReduced/assembly.fasta
prodigal \
  -a spruceReducedMicrobiomeMetagenome.genes.faa \
  -d spruceReducedMicrobiomeMetagenome.genes.fna \
  -f gff \
  -o spruceReducedMicrobiomeMetagenome.genes.gff \
  -i $hostReducedAssembly

grep -c "^>" spruceReducedMicrobiomeMetagenome.genes.faa ## 97122 genes

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/nonHostReadAssembly/
nonHostAssembly=/vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/nonHostReadAssembly/assembly.fasta

prodigal \
  -a spruceRemovedMicrobiomeMetagenome.genes.faa \
  -d spruceRemovedMicrobiomeMetagenome.genes.fna \
  -f gff \
  -o spruceRemovedMicrobiomeMetagenome.genes.gff \
  -i $nonHostAssembly

grep -c "^>" spruceRemovedMicrobiomeMetagenome.genes.faa ## 4687. Huh. Trying to remove host may be a bad idea.

## get local and send off to kegg for fun:

clear
ls -l /vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/hostReduced/spruceReducedMicrobiomeMetagenome.genes.faa
ls -l /vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/nonHostReadAssembly/spruceRemovedMicrobiomeMetagenome.genes.faa

#path2get=/vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/hostReduced/spruceReducedMicrobiomeMetagenome.genes.faa
path2get=/vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/nonHostReadAssembly/spruceRemovedMicrobiomeMetagenome.genes.faa
scp -rP 30419 -i ~/.ssh/id_ed25519 ubuntu@129.70.51.6:$path2get .

ls /home/test/.ssh/lab2denbi

## back to binning. Try using the same 3 softwares as the class. 

## metabat2 install
conda create -n metabat2 -c bioconda metabat2

## concoct install

#conda config --add channels defaults
#conda config --add channels bioconda
#conda config --add channels conda-forge
conda create -n concoct -c bioconda python=3 concoct

## nope. still issues with scitkit learn as before.

## we can try what we did with the class - use a yaml file:
conda env create -f concoct.yml

## this is the yaml file I used:

##############################
name: concoct
channels:
  - conda-forge
  - bioconda
dependencies:
  - concoct=1.1.0
  - libopenblas=*=openmp*
  - mkl
  - python>=3
  - samtools>=1.9
  - scikit-learn=1.1.*
variables:
  USE_OPENMP: 1
##############################

## seems to work ok...

## vamb install
conda create -n vamb -c bioconda vamb minimap2
## seems okay, but really out of date. Let's 
## try with pip:

conda remove -n vamb --all

conda deactivate

## let's try without conda, as recommended by the developers:

pip install vamb ## and fails. jeezus. try in a conda environment

conda create -n vamb 

## ugh, not working. Try github:

conda create -n vamb python=>=3.9.0

conda activate vamb 

cd /vol/piceaNanopore

git clone https://github.com/RasmussenLab/vamb -b master

cd vamb

pip install -e .

## maxbin install (??)
## just curious, did maxbin2 ever fix it's issues?

conda install -c bioconda maxbin2

## failed 

## taking forever. anyway, we got three. 

## das tool install

conda create -n das_tool -c bioconda das_tool

DAS_Tool
## seems okay

## metabat2 binning

conda activate metabat2


## hostRemoved

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostRemoved
readsHostRemoved=/vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/nonHostReads.fastq
assemblyHostRemoved=/vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/nonHostReadAssembly/assembly.fasta 

## for our nanopore alignments we use minimap
minimap2 -d assemblyHostRemoved.mmi $assemblyHostRemoved # make index

## make the alignments,
## following: https://github.com/RasmussenLab/vamb/blob/master/README.md

minimap2 -t 25 -ax map-ont assemblyHostRemoved.mmi --split-prefix mmsplit $readsHostRemoved -R @RG\\tID:thisIsAreadGroup | samtools view -F 3584 -b --threads 25 > hostRemovedAligned2Contigs.bam


minimap2 -t 25 -ax map-ont assemblyHostRemoved.mmi --split-prefix mmsplit $readsHostRemoved | samtools view -F 3584 -b --threads 25 > hostRemovedAligned2Contigs.bam

## this fails. formatting issues with on-the-fly-SAM file, it seems. Don't want to spend time 
## debugging, I think such a small metagenome can't be useful for mags, anyway. 

## not sure if the other, larger file will be any better, but gotta try:

## hostReduced
cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced
readsHostReduced=/vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/allChrisHostDepletionTrial_noShorts.fastq
assemblyHostReduced=/vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/hostReduced/assembly.fasta 

## for our nanopore alignments we use minimap
minimap2 -d assemblyHostReduced.mmi $assemblyHostReduced # make index

## make the alignments, takes 

minimap2 -t 25 -ax map-ont assemblyHostReduced.mmi -I30g --split-prefix mmsplit $readsHostReduced | samtools view -F 3584 -b --threads 25 > hostReducedAligned2Contigs.bam

## not working...why not?
minimap2 -t 25 -ax map-ont assemblyHostReduced.mmi \
  -I30g \
  -o test.sam \
  --split-prefix mmsplit \
  $readsHostReduced 

## first read is 
22374732-69a0-477f-b5de-1d7fbfba33fa

## that seems fine, so I guess it is the second part of the pipe
## that is breaking?

## checking out that flag combination 
## (using superhandy site here: http://broadinstitute.github.io/picard/explain-flags.html)

## read fails platform/vendor quality checks (0x200) 512
## read is PCR or optical duplicate (0x400) 1024
## supplementary alignment (0x800) 2048
512+1024+2048  = 3584

## anyway, that's not the issue. samtools just fails generally with it:

samtools view test.sam

samtools view -H test.sam

## seems like the headers for all of our alignments 
## are duplicated? 

grep scaffold_3628 test.sam

grep scaffold_3628 $assemblyHostReduced

## are these duplicated with our assembly?

grep ">" $assemblyHostReduced | sort > dupsInAss.txt
grep ">" $assemblyHostReduced | sort | uniq -d ## none?
grep ">" $assemblyHostReduced | sort | uniq -c > dupsInAss.txt ## really can't find these...

## why is minimap creating a double header entry?

## will this go away if we switch to fasta for the queries?
seqtk seq -A $readsHostReduced > allChrisHostDepletionTrial_noShorts.fasta

minimap2 -t 25 -ax map-ont assemblyHostReduced.mmi \
  -I30g \
  -o test.sam \
  --split-prefix mmsplit \
  allChrisHostDepletionTrial_noShorts.fasta

samtools view test.sam ## still same problem

grep contig_999 test.sam

grep -n "SN:contig_1002" test.sam ## 1, 4777

grep -n 22374732-69a0-477f-b5de-1d7fbfba33fa test.sam  ## 9552

## starting on line 4777, all headers are repeated. Information starts
## again on 9552. So can we delete lines 4777-9551? 

## ok, last resort, let's delete them and see what happens

samtools view test.sam ## works

samtools view -hF 3584 --threads 25 test.sam > hostReducedAligned2Contigs.sam

## seems to work. weird. Hope this doesn't cause any downstream issues.

less $assemblyHostReduced 

## sort and index the alignment. nanopore takes much more time than the illumina reads
samtools sort -l 1 \
    -n \
    -@25 \
    -o hostReducedAligned2ContigsSorted.bam \
    -O BAM \
    hostReducedAligned2Contigs.sam

## vamb tools requires sorting by name, so can't can't index it:
samtools index -@ 25 ./hostReducedAligned2ContigsSorted.bam ## throws errors

## concoct needs sorting by coordinates, not name ("-n" above)

## redo for concoct:
samtools sort -l 1 \
    -@25 \
    -o hostReducedAligned2ContigsSortedforConcoct.bam \
    -O BAM \
    hostReducedAligned2Contigs.sam
samtools index -@ 25 ./hostReducedAligned2ContigsSortedforConcoct.bam 

## go forward with metabat
conda activate metabat2

mkdir metabat

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/metabat


## define our variables

assembly="/vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/hostReduced/assembly.fasta"
bam="/vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/hostReducedAligned2ContigsSorted.bam"
otherBam="/vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/hostReducedAligned2ContigsSortedforConcoct.bam"

## run the program
runMetaBat.sh $assembly $bam

## that produced nothing. Try with a differently formatted bam: 
runMetaBat.sh $assembly $otherBam

## nope, no bins. 

## try the others...

conda deactivate

conda activate vamb

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced

## let's redo the above alignments...

assemblyHostReduced=/vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/hostReduced/assembly.fasta 
reads=/vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/allChrisHostDepletionTrial_noShorts.fastq 
alignment=
readsAligned2Assembly4vamb.bam

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/vambOut

wget https://raw.githubusercontent.com/RasmussenLab/vamb/37277e23fa1b28718eca4c6a5daa958f42758b13/src/concatenate.py

python3 concatenate.py vambHostReducedHostAssembly.fna.gz $assemblyHostReduced 
minimap2 -d catalogue.mmi vambHostReducedHostAssembly.fna.gz # make index

minimap2 -t 25 -ax map-ont catalogue.mmi \
  -I30g \
  -o intermediateVambRead2AssemblyAlignments.sam \
  --split-prefix mmsplit \
  $reads

samtools view -F 3584 -b --threads 20 intermediateVambRead2AssemblyAlignments.sam > readsAligned2Assembly4vamb.bam

## has the same problems with duplicated headers as before

grep -n "SN:S1Ccontig_1002" intermediateVambRead2AssemblyAlignments.sam ## 1, 4111

## our first read is here:
grep -nB 2 22374732-69a0-477f-b5de-1d7fbfba33fa intermediateVambRead2AssemblyAlignments.sam  ## line 8220 reads start

## looks like our last header should be:
grep -n -A1 -B2 "SN:S1Cscaffold_3628" intermediateVambRead2AssemblyAlignments.sam ## 4109, 8219

## line 4110 has the PG info, keep it

## we should be able to remove these duplicate headers:
sed '4111, 8219d' intermediateVambRead2AssemblyAlignments.sam > intermediateVambRead2AssemblyAlignments_deDup.sam

## try again 
samtools view -F 3584 -b --threads 20 intermediateVambRead2AssemblyAlignments_deDup.sam \
> readsAligned2Assembly4vamb.bam

## vamb is complaining about sorting...

samtools sort -l 1 \
    -@25 \
    -o readsAligned2Assembly4vambSorted.bam \
    -O BAM \
    readsAligned2Assembly4vamb.bam

## seems to work. Weird, don't know why mininmap is creating duplicate headers. 
## anyway, try vamb again:

rm -r hostReducedVambOut/

conda deactivate 

conda activate vamb
cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/vambOut/
assemblyHostReduced=/vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/vambOut/vambHostReducedHostAssembly.fna.gz
alignment=/vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/vambOut/readsAligned2Assembly4vambSorted.bam
vamb --outdir hostReducedVambOut \
  --fasta $assemblyHostReduced \
  --bamfiles $alignment \
  --minfasta 250000 \
  -t 8  &


cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/vambOut/hostReducedVambOut/bins

## concoct

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/

conda activate concoct 

assembly="/vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/hostReduced/assembly.fasta"
readAlignments="/vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/hostReducedAligned2ContigsSortedforConcoct.bam"
outdir="/vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/concoct/"

cut_up_fasta.py $assembly -c 10000 -o 0 --merge_last -b concoctContigs_10K.bed > concoctContigs_10K.fa
concoct_coverage_table.py concoctContigs_10K.bed $readAlignments > coverage_table.tsv

concoct \
  --composition_file concoctContigs_10K.fa \
  --coverage_file coverage_table.tsv \
  -t 25 \
  -b $outdir

cd $outdir
merge_cutup_clustering.py clustering_gt1000.csv > clustering_merged.csv

mkdir concoct_bins

extract_fasta_bins.py $assembly clustering_merged.csv --output_path concoct_bins

## change names:
cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/concoct/concoct_bins

for i in *; do
  mv $i "concoct_$i"
done

## example: concoct_15.fa

## well, concoct found a lot of bins. most of them are probably trash, but...
## vamb also found some. what happened to metabat?

## checked again, and metabat is a no-go

## let's try das_tool on just the two sets of bins that we have.

conda deactivate 

conda activate das_tool

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/refine

concoctBins=/vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/concoct/concoct_bins
vambBins=/vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/vambOut/hostReducedVambOut/bins
assembly=/vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/hostReduced/assembly.fasta

ls $concoctBins
ls $vambBins
ls $assembly


find . -name Fasta_to_Contig2Bin.sh 

## concoct:
Fasta_to_Contig2Bin.sh \
    -e fa \
    -i $concoctBins \
    > concoct.contigs2bin.tsv

head concoct.contigs2bin.tsv ## that looks okay

## vamb
Fasta_to_Contig2Bin.sh \
    -e fna \
    -i $vambBins \
    > vamb.contigs2bin.tsv

head vamb.contigs2bin.tsv ## "S1C" is appended, like before, need to get rid of these

## we need to cut the first three letters out of or so...
cut --complement -c 1-3 vamb.contigs2bin.tsv > vamb.contigs2bin_edited.tsv

less vamb.contigs2bin_edited.tsv ## better

DAS_Tool  -i concoct.contigs2bin.tsv,vamb.contigs2bin_edited.tsv \
    -l concoct,vamb \
    -c $assembly \
    -t 25 \
    --write_bins \
    --score_threshold=0.1 \
    -o hostReducedBinsRefined

## hah, even with that low threshold, one genome 
## survives:

/vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/refine/hostReducedBinsRefined_DASTool_bins/concoct_76.fa

## surprised it was a concoct genome that survived...does order matter?

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/refine/dasOut
DAS_Tool  -i ../vamb.contigs2bin_edited.tsv,../concoct.contigs2bin.tsv \
    -l vamb,concoct \
    -c $assembly \
    -t 25 \
    --write_bins \
    --score_threshold=0.1 \
    -o hostReducedBinsRefined

## I'm assuming this either a organelle or the remnants of the host...

less /vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/refine/dasOut/hostReducedBinsRefined_DASTool_bins/concoct_76.fa
## that is a chloroplast genome...of course

## briefly checking the other VAMB bins...

## vae_17.fna has matches to a walking stick (Timema) genome? wtf
## plus a rrna 5s subunit match to a cedar tree? double wtf. 
## anyway, some weird stuff

## hope dies last maybe best to try phyllophlan and checkM on these things.

## checkM

#conda config --set channel_priority flexible
conda create -n checkm -c bioconda checkm-genome
#conda config --set channel_priority strict

conda deactivate
conda activate checkm

## variables

## we can put our checkm outputs here

checkMout="/vol/piceaNanopore/dan/chrisHostDepletionTrial/qualityCheck/"

cd $checkMout

concoctBins=/vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/concoct/concoct_bins

vambBins=/vol/piceaNanopore/dan/chrisHostDepletionTrial/binning/hostReduced/vambOut/hostReducedVambOut/bins

nohup checkm lineage_wf -t 15 $vambBins qcVamb &> vambCheckm.log &

nohup checkm lineage_wf -t 15 $concoctBins -x fa  qcConcoctBins  &> concoctCheckm.log &

ls $concoctBins 

## looks pretty dismal. MAGs are not possible here. 

## vae_3175 may be mitochondrial

## phylophlan

conda config --set channel_priority flexible
conda create --name phylophlan -c bioconda phylophlan
conda config --set channel_priority strict


## find Chris's run which did not use adaptive sequencing 
## (the one used for simulations). 
## try metagenome assembly and prediction of bacterial genes?

## in both, include an alignment of all genes to mitochondrial 
## and chloroplast genomes of spruce.

## see if there is a significant in prokaryotic genes recovered.  

## I guess the best yardstick here is the number of prokaryotic
## and fungal genes, 

## the easieast is the bacterial genes. 

## where is chris's data, that we used for simulations of the spruce?


## i think it is this?:


ls -lh /media/vol2/chris/Pabies_tests/bulk_fast5_files/MinION-PC_20230621_1522_FAU29445_MN40608_sequencing_run_bigger_e77dd4cd_5395a225.fast5

cd /media/vol2/chris/Pabies_tests/bulk_fast5_files/

## but where is the fastq for this?
cd /var/lib/minknow/data/Pabies_bulk_fast5/bigger/20230621_1517_MN40608_FAU29445_e77dd4cd

## make a combined pass fastq for this, put it on denbi:

cd /var/lib/minknow/data/Pabies_bulk_fast5/bigger/20230621_1517_MN40608_FAU29445_e77dd4cd/fastq_pass/


## put this on denbi:
path2get=/var/lib/minknow/data/Pabies_bulk_fast5/bigger/20230621_1517_MN40608_FAU29445_e77dd4cd/fastq_pass/allpabies_noAdaptSeq.fastq
path2put="/vol/piceaNanopore/dan/chrisHostDepletionTrial/compareAdapt/"
scp -rP 30419 -i ~/.ssh/lab2denbi $path2get ubuntu@129.70.51.6:$path2put 

## looks like it only ran for 4 hours:
less /var/lib/minknow/data/Pabies_bulk_fast5/bigger/20230621_1517_MN40608_FAU29445_e77dd4cd/final_summary_FAU29445_e77dd4cd_5395a225.txt

## huh, there are only 24 584 reads in our pabies simulation fastq file...seems small.

## not sure if this will be comparable. where is the equivalent fastq_pass for our actual spruce depletion experiment

## here, on the lab comp

/var/lib/minknow/data/repeatingDansStuff1/21_7_23/20230721_1214_MN40608_FAS81869_d4801a32/fastq_pass

## our sequence experiment for exclusion, where adaptive seqencincg "worked":
ls /var/lib/minknow/data/repeatingDansStuff1/21_7_23/20230721_1214_MN40608_FAS81869_d4801a32


## to convince myself that this worked, I want to compare the number of prokaryotic genes that come out 
## an assembly from the non-adptive-seq sequencing run, and the adaptive seq run:


cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/hostReduced/

## remind me, how many prok genes does prodigal think we have?:
grep -c "^>" spruceReducedMicrobiomeMetagenome.genes.faa ## 97122, lots but how many are not from mitochondria and chloroplasts?


## while we're here, grab these faa and send to ghost koala:
path2get=/vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/hostReduced/spruceReducedMicrobiomeMetagenome.genes.faa
scp -rP 30419  ubuntu@129.70.51.6:$path2get . 

## let's try an assembly with the  

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/compareAdapt/

conda activate flye

reads=/vol/piceaNanopore/dan/chrisHostDepletionTrial/compareAdapt/allpabies_noAdaptSeq.fastq
outdir=/vol/piceaNanopore/dan/chrisHostDepletionTrial/compareAdapt/allpabies_noAdaptSeq_assembly/
#mkdir -p $outdir

nohup flye --meta \
    --nano-raw $reads \
    --threads 25 \
    --out-dir $outdir \
    &> allpabies_noAdaptSeq_assembly.log &

## and of course it fails.

## remind myself why I don't filter reads through the picea genome again? 
## one thing (maybe the first?) to report is simply the number of reads 
## that don't map to host+organelles well

spruceGenome=/vol/piceaNanopore/dan/chrisHostDepletionTrial/spruceRefGenome/Pabies-haploid_withOrganelles.fa
noAdaptReads=/vol/piceaNanopore/dan/chrisHostDepletionTrial/compareAdapt/allpabies_noAdaptSeq.fastq
cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/compareAdapt/
nohup minimap2  -I100g -t 20 -ax map-ont $spruceGenome $noAdaptReads 1> noAdaptSeq_Align2Spruce.sam 2> noAdaptSeq_Align2Spruce.log &

## the same process, using our adaptive seq reads:
spruceGenome=/vol/piceaNanopore/dan/chrisHostDepletionTrial/spruceRefGenome/Pabies-haploid_withOrganelles.fa
yesAdaptReads=/vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/allChrisHostDepletionTrial_noShorts.fastq
cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/compareAdapt/
nohup minimap2  -I100g -t 25 -ax map-ont $spruceGenome $yesAdaptReads 1> adaptSeq_Align2Spruce.sam 2> adaptSeq_Align2Spruce.log &

## these will result in both unmapped reads and poorly mapped reads.
## I guess we take only the best reads and try assembling these:

samtools view -q 50 --threads 20 noAdaptSeq_Align2Spruce.sam > noAdapt_hostReads.sam

cut -f1 noAdapt_hostReads.sam | wc -l ## 55817
cut -f1 noAdapt_hostReads.sam | uniq | wc -l ## 19391 
cut -f1 noAdapt_hostReads.sam | uniq > noAdapt_hostReadNames.txt 

wc -l noAdapt_hostReadNames.txt ## 19391

wc -l allpabies_noAdaptSeq.fastq ## 98336 / 4 = 24584 reads

## 24584 - 19391 = 5193 reads that don't align well to host. 
5193 / 24584 ## .211, or 21% 
## get a fasta for these:

grep "^@" allpabies_noAdaptSeq.fastq | cut --complement -c 1 | cut -f1 -d" " > allpabies_noAdaptSeq_names.txt

sort <(cat allpabies_noAdaptSeq_names.txt noAdapt_hostReadNames.txt) | uniq -u > noAdapt_nonHost_readNames.txt 

wc -l noAdapt_nonHost_readNames.txt ## 5193, as expected. 

seqtk subseq allpabies_noAdaptSeq.fastq noAdapt_nonHost_readNames.txt > pAbies_noAdapt_nonHost.fastq 

wc -l pAbies_noAdapt_nonHost.fastq  ## makes sense

## does it make sense to try to assemble these?
conda activate flye

reads=pAbies_noAdapt_nonHost.fastq
outdir=pAbies_noAdapt_nonHost/
#mkdir -p $outdir
nohup flye --meta \
    --nano-raw $reads \
    --threads 25 \
    --out-dir $outdir \
    &> allpabies_noAdaptSeq_assembly.log &
## fails

## repeat with host reduced dataset
samtools view -q 50 --threads 20 adaptSeq_Align2Spruce.sam > adapt_hostReads.sam

cut -f1 adapt_hostReads.sam | uniq > adapt_hostReadNames.txt 

wc -l adapt_hostReadNames.txt


yesAdaptReads=/vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/allChrisHostDepletionTrial_noShorts.fastq

head $yesAdaptReads 

grep -c "^@.* runid" $yesAdaptReads  ## 1251333

wc -l $yesAdaptReads  ## 5005332 / 4 = 1251333

grep "^@.* runid" $yesAdaptReads | cut --complement -c 1 | cut -f1 -d" " > allpabies_adaptSeq_names.txt

wc -l allpabies_adaptSeq_names.txt ## 1251333 looks good

sort <(cat allpabies_adaptSeq_names.txt adapt_hostReadNames.txt) | uniq -u > adapt_nonHost_readNames.txt 

wc -l adapt_nonHost_readNames.txt ## 247594 reads

seqtk subseq $yesAdaptReads adapt_nonHost_readNames.txt > pAbies_adapt_nonHost.fastq 

grep -c "^@.* runid" pAbies_adapt_nonHost.fastq  ## 247594
grep -c "^@.* runid" $yesAdaptReads  ## 1251333

1251333 - 247594 ## 1003739

247594/1251333 ## 19% 


## does it make sense to try to assemble these?
conda activate flye

reads=pAbies_adapt_nonHost.fastq
outdir=pAbies_adapt_nonHost/
#mkdir -p $outdir

nohup flye --meta \
    --nano-raw $reads \
    --threads 25 \
    --out-dir $outdir \
    &> allpabies_adaptSeq_assembly.log &

## does it make any sense to run gene predictions on the raw reads?

## can't hurt, I guess:

mkdir -p genePreds/noAdapt_nonHost_genes


cd genePreds/noAdapt_nonHost_genes

## make a fasta
seqtk seq -A /vol/piceaNanopore/dan/chrisHostDepletionTrial/compareAdapt/pAbies_noAdapt_nonHost.fastq > pAbies_noAdapt_nonHost.fasta

conda activate prodigal

reads=/vol/piceaNanopore/dan/chrisHostDepletionTrial/compareAdapt/genePreds/noAdapt_nonHost_genes/pAbies_noAdapt_nonHost.fasta


prodigal \
  -a pAbies_noAdapt_nonHost.genes.faa \
  -d pAbies_noAdapt_nonHost.genes.fna \
  -f gff \
  -o pAbies_noAdapt_nonHost.genes.gff \
  -i $reads

grep -c ">" pAbies_noAdapt_nonHost.genes.fna ## 11356 genes, from a 13M file

## file size is actually 12985120 bytes
11356/13 = 873.5 #gene/M
11356/12985120 = 0.0008745394728735661 ## gene/byte
12985120/11356 = 1143 ## bytes/gene

## repeat with adaptive seq

cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/compareAdapt/

reads=/vol/piceaNanopore/dan/chrisHostDepletionTrial/compareAdapt/pAbies_adapt_nonHost.fastq
seqtk seq -A $reads > pAbies_noAdapt_nonHost.fasta


cd genePreds/adapt_nonHost_genes

seqtk seq -A /vol/piceaNanopore/dan/chrisHostDepletionTrial/compareAdapt/pAbies_adapt_nonHost.fastq > pAbies_adapt_nonHost.fasta

reads=/vol/piceaNanopore/dan/chrisHostDepletionTrial/compareAdapt/genePreds/adapt_nonHost_genes/pAbies_adapt_nonHost.fasta

prodigal \
  -a pAbies_adapt_nonHost.genes.faa \
  -d pAbies_adapt_nonHost.genes.fna \
  -f gff \
  -o pAbies_adapt_nonHost.genes.gff \
  -i $reads

grep -c ">" pAbies_adapt_nonHost.genes.fna ## 610658 prokaryotic genes predicted from these adaptive seq non-host reads

## 672778641 bytes or ~ 642M

610658/642 = 951.18

610658/672778641 = 0.000907665557117471

672778641/610658 = 1101.7 ## bytes/gene


cd /vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/


grep -c "^@.* runid=" fastq_pass/allChrisHostDepletionTrial_pass.fastq ## 1,664,477 reads, 12gig

## I don't really understand. The unblocked read file has 617842 sequences,
## the unblocked read file has 617,842 reads, but not all passed read quality..

grep -c "^@.* runid=" allChrisHostDepletionTrial_noShorts.fastq ## 1,251,333 reads, 11gig

## somehow, rejecting 600000 reads didn't improve our ratio of non-host reads?

## probably several things at play here, not the least that we are comparing a 
## tiny run to a big run. 


ls -lh /vol/piceaNanopore/dan/chrisHostDepletionTrial/assemblies/hostReduced/assembly.fasta

ls -lh /vol/piceaNanopore/dan/chrisHostDepletionTrial/compareAdapt/pAbies_adapt_nonHost/assembly.fasta

grep -c "^>" /vol/piceaNanopore/dan/chrisHostDepletionTrial/compareAdapt/pAbies_adapt_nonHost/assembly.fasta
## metagenome with 618 reads? 5.2M?  ugh

## may


cd /vol/piceaNanopore/dan/bactGenomes/genbank

wget ftp://ftp.ncbi.nih.gov/genomes/genbank/bacteria/assembly_summary.txt

wc -l /vol/piceaNanopore/dan/bactGenomes/genbank/assembly_summary.txt ## 1696420

wget ftp://ftp.ncbi.nlm.nih.gov/genomes/README_assembly_summary.txt

cd /vol/piceaNanopore/dan/bactGenomes/refSeq
wget ftp://ftp.ncbi.nih.gov/genomes/refseq/bacteria/assembly_summary.txt

wc -l /vol/piceaNanopore/dan/bactGenomes/refSeq/assembly_summary.txt ## 310753

## seems like the genbank one is much bigger, though probably of much lower quality...
## let's start with the refseq one.

cd /vol/piceaNanopore/dan/bactGenomes/refSeq

## let's assume they're all good:

sed '1,2d' assembly_summary.txt | cut  -f 20  > ncbiRefGenomes.txt

## but this doesn't give us the actual file, gives us the ftp folder, and wget 
## isn't being allowed to recursively download


head ncbiRefGenomes.txt

cut -d"/" -f 10  ncbiRefGenomes.txt > genNames.txt
## add the file ending
sed -i 's/.*/&_genomic.fna.gz/' genNames.txt
paste ncbiRefGenomes.txt genNames.txt -d"/" > files2download.txt

## these seem to work when I try them manually. Can we do a big download

nohup wget  -i files2download.txt &> downloadRefSeq.log &

wc -l files2download.txt

## revisiting this, it looks like we got a lot of pseudomonas aerigenosus, helicobacter, and campylobacter

grep ">" bactRefGenome.fa | cut -f2 -d" " 

grep ">" bactRefGenome.fa | cut -f2 -d" " | sort | uniq | wc -l

## can we balance this out a bit?

cd /vol/piceaNanopore/dan/bactGenomes

cut -f8 assembly_summary.txt | sort | uniq > bactGenomeNames_uniq.txt

cut -f8 assembly_summary.txt | cut -f1,2 -d" " | sort | uniq | wc -l ## ~20,000 species

cut -f8 assembly_summary.txt | cut -f1,2 -d" " | sort | uniq > allBactSpeciesList.txt 
sed -i '1d' allBactSpeciesList.txt 

sed '1d' assembly_summary.txt > assembly_summary.tsv  

## how can we use this to get ~fair representation? this is probably a job for python...

python3
import pandas as pd
import os
speciesList=pd.read_csv('allBactSpeciesList.txt')
assembly_summary=pd.read_csv('assembly_summary.tsv', sep='\t')

assembly_summary.columns

assembly_summary.head()

       
assembly_summary[['taxid','isolate', 'species_taxid', 'organism_name']].iloc[1:40,:]


## looks like the best bet is to use the species_taxid column:
      
assembly_summary['organism_name'].drop_duplicates().shape

## so this should give us a list of the first instance of 
## each unique organism name:

firstInstances = ~assembly_summary['organism_name'].duplicated(keep='first')


assembly_summary[ firstInstances ]['organism_name']

## for the moment, let's say we want one genome from each 
## so the new download list should be:

assembly_summary[ firstInstances ]['ftp_path'].to_csv('allSppDownloadlist.csv', index=False, header=False )

## out of python, let's reuse our code from above to edit the ftp paths:

cd /vol/piceaNanopore/dan/bactGenomes
cut -d"/" -f 10 allSppDownloadlist.csv > genNames.txt
sed -i 's/.*/&_genomic.fna.gz/' genNames.txt
paste allSppDownloadlist.csv genNames.txt -d"/" > files2download.txt

## try a new download, which will surely run all weekend:
cd /vol/piceaNanopore/dan/bactGenomes/
getFiles=/vol/piceaNanopore/dan/bactGenomes/files2download.txt
putFiles=/vol/piceaNanopore/dan/bactGenomes/refSeq/
nohup wget -i $getFiles -P $putFiles &> downloadRefSeq.log &


## repeat all the above with fungi:

cd /vol/piceaNanopore/dan/fungalGenomes

wget ftp://ftp.ncbi.nlm.nih.gov/genomes/README_assembly_summary.txt

wget ftp://ftp.ncbi.nih.gov/genomes/genbank/fungi/assembly_summary.txt

cut -f8 assembly_summary.txt | cut -f1,2 -d" " | sort | uniq | wc -l ## ~4300 fungal species

sed '1d' assembly_summary.txt > assembly_summary.tsv  

sed '1d' assembly_summary.txt > assembly_summary.tsv  

## back into python

python3
import pandas as pd
import os

#assembly_summary=pd.read_csv('assembly_summary.tsv', sep='\t')
## error parsing line 10465. Back out to shell
sed -n '10465p' assembly_summary.tsv ## ah, this record has errors
## we don't really need any information after the ftp address, anyway:
cut -f1-20 assembly_summary.tsv > assembly_summary_cleaned.tsv 

## back in python:
assembly_summary=pd.read_csv('assembly_summary_cleaned.tsv', sep='\t')

assembly_summary['organism_name'].drop_duplicates().shape ## almost 600 genomes...

firstInstances = ~assembly_summary['organism_name'].duplicated(keep='first')
assembly_summary[ firstInstances ]['ftp_path'].to_csv('allSppDownloadlist.csv', index=False, header=False )

## out of python
cd /vol/piceaNanopore/dan/fungalGenomes
cut -d"/" -f 10 allSppDownloadlist.csv > genNames.txt
sed -i 's/.*/&_genomic.fna.gz/' genNames.txt
paste allSppDownloadlist.csv genNames.txt -d"/" > files2download.txt

## try a new download, which will surely run all weekend:
cd /vol/piceaNanopore/dan/fungalGenomes/

getFiles=/vol/piceaNanopore/dan/fungalGenomes/files2download.txt
putFiles=/vol/piceaNanopore/dan/fungalGenomes/refSeq/
nohup wget -i $getFiles -P $putFiles &> downloadRefSeq.log &

## now, we need to make a blast database 


### let that run for a while...

## let's work in the large ephemeral drive that denbi gave us:

## let's a database of our fungal genomes and bacterial genomes

#mv /vol/piceaNanopore/dan/bactGenomes /mnt/ephem/
#mv /vol/piceaNanopore/dan/fungalGenomes /mnt/ephem/

#mv /mnt/ephem/fungalGenomes /vol/piceaNanopore/dan/ 
#mv /vol/piceaNanopore/dan/fungalGenomes/refSeq /mnt/ephem/fungalGenomes

du /vol/piceaNanopore/dan/fungalGenomes/refSeq  -h


cd /mnt/ephem/bactGenomes/refSeq

gunzip -r .

cd /mnt/ephem/fungalGenomes/refSeq

gunzip -r . &


conda create -n blast -c bioconda blast

conda activate blast

cd /mnt/ephem/bactGenomes/refSeq 

nohup cat * > bactRefGenome.fa & ## too many files

## try this:

ls /mnt/ephem/bactGenomes/refSeq 

## make bact combined file
cd /vol/piceaNanopore/dan/bactGenomes

nohup find /mnt/ephem/bactGenomes/refSeq -type f -exec cat {} + > allbactGenomes.fa &
grep -c "^>" allbactGenomes.fa > howmanybact.txt &

cat /vol/piceaNanopore/dan/bactGenomes/howmanybact.txt

## make fungal combined file
cd /vol/piceaNanopore/dan/fungalGenomes
nohup find /mnt/ephem/fungalGenomes/refSeq -type f -exec cat {} + > allFungalGenomes.fa &

## should be 5977 genomes in this file:
grep -c "^>" allFungalGenomes.fa > howmanyfungi.txt &

cat /vol/piceaNanopore/dan/fungalGenomes/howmanyfungi.txt

## make databases

## bacterial blastdb
conda activate blast

cd /vol/piceaNanopore/dan/bactGenomes

nohup makeblastdb -in allbactGenomes.fa -parse_seqids -dbtype nucl &

## fungal blastdb

cd /vol/piceaNanopore/dan/fungalGenomes
nohup makeblastdb -in allFungalGenomes.fa -parse_seqids -dbtype nucl &


## raw reads blasted against bacteria:
## we are interested in blasting the raw reads, and the assemblies we have.

cd /vol/piceaNanopore/dan/bactGenomes

rawReadsAdapt=/vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/allChrisHostDepletionTrial_noShorts.fasta
nohup blastn -db allbactGenomes.fa \
  -query $rawReadsAdapt \
  -num_threads 10 \
  -num_alignments 1 \
  -out depletionTrial_bacterial_blastn.csv \
  -outfmt 10 &


sed -i '1i qseqid,sseqid,pident,length,mismatch,gapopen,qstart,qend,sstart,send,evalue,bitscore' $genome"_"$query"_Blastn.csv"

## not sure how to get multiple output formats without running multiple alignments? 
## seems really inefficient but rerun with 

nohup blastn -db allbactGenomes.fa \
  -query $rawReadsAdapt \
  -num_threads 10 \
  -num_alignments 3 \
  -out depletionTrial_bacterial_blastn.txt &


head /vol/piceaNanopore/dan/bactGenomes/depletionTrial_bacterial_blastn.csv

ls -lh /vol/piceaNanopore/dan/bactGenomes/depletionTrial_bacterial_blastn.csv

less /vol/piceaNanopore/dan/bactGenomes/depletionTrial_bacterial_blastn.csv

wc -l /vol/piceaNanopore/dan/bactGenomes/depletionTrial_bacterial_blastn.csv

cd /vol/piceaNanopore/dan/bactGenomes

less allbactGenomes.fa

bactTxt=/vol/piceaNanopore/dan/bactGenomes/depletionTrial_bacterial_blastn.txt

ls -lh  $bactTxt

grep -c "Query=" $bactTxt

grep -c "No hits found" $bactTxt

grep -c "Sequences producing significant alignments:" $bactTxt

less $bactTxt

bactCSV=/vol/piceaNanopore/dan/bactGenomes/depletionTrial_bacterial_blastn.csv

wc -l $bactCSV

ls -lh  $bactCSV

grep -c "^>" $rawReadsAdapt

125139/319718

116775/298013 

113619 / 290154

111364/284570

96783/245790

89776/227539 ## seems to hover around 39% 

## looks like it is working...

## fungal genomes

## blast them too!

## we only have enough cores to start one:

cd /vol/piceaNanopore/dan/fungalGenomes

rawReadsAdapt=/vol/piceaNanopore/dan/chrisHostDepletionTrial/nanoporeRunData/allChrisHostDepletionTrial_noShorts.fasta

nohup blastn -db allFungalGenomes.fa \
  -query $rawReadsAdapt \
  -num_threads 5 \
  -num_alignments 1 \
  -out depletionTrial_fungal_blastn.csv \
  -outfmt 10 &

sed -i '1i qseqid,sseqid,pident,length,mismatch,gapopen,qstart,qend,sstart,send,evalue,bitscore' $genome"_"$query"_Blastn.csv"

nohup blastn -db fungRefGenome.fa \
  -query $rawReadsAdaptFa \
  -num_threads 10 \
  -num_alignments 3 \
  -out depletionTrial_fungal_blastn.txt &

## check these:

## there are some repeats. For instance

grep -A 1 "5d61c9f3-3592-4123-80aa-b87bad800aac" $rawReadsAdapt

grep "5d61c9f3-3592-4123-80aa-b87bad800aac" /vol/piceaNanopore/dan/bactGenomes/depletionTrial_bacterial_blastn.csv

grep -A 40 "5d61c9f3-3592-4123-80aa-b87bad800aac" /vol/piceaNanopore/dan/bactGenomes/depletionTrial_bacterial_blastn.txt

grep "5d61c9f3-3592-4123-80aa-b87bad800aac" /vol/piceaNanopore/dan/fungalGenomes/depletionTrial_fungal_blastn.csv

## so I think we need to combine the reads that blasted to either fungal or bacterial genomes 
## with high confidence, and sort out the unique reads from this. 

## for the moment, let's not do much curation on this, just get an estimate of reads that are likely 
## microbial in origin

## compare to our small control, when Chris 

